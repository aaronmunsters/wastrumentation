{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# General Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Install the dependencies if not installed yet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "using Pkg\n",
        "# Pkg.add(\"CSVFiles\")\n",
        "# Pkg.add(\"VegaLite\")\n",
        "# Pkg.add(\"DataFrames\")\n",
        "\n",
        "using Statistics, Printf\n",
        "using VegaLite, CSVFiles, DataFrames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "target_dir_prefix = \"./working-dir/dragonfly-25-01-07/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Compatibility\n",
        "Read in `.csv` data files from what works and what does not"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "function parse_boolean(s::String)\n",
        "    if s === \"False\" return false\n",
        "    elseif s === \"True\" return true\n",
        "    else error(\"Cannot parse $s as boolean\")\n",
        "    end\n",
        "end\n",
        "\n",
        "function parse_booleans(df)\n",
        "    df = transform(df, :exception => ByRow(parse_boolean) => :exception)\n",
        "    df = transform(df, :timeout => ByRow(parse_boolean) => :timeout)\n",
        "    df\n",
        "end\n",
        "\n",
        "exec_once = DataFrame(load(target_dir_prefix * \"executes-once.csv\")) |> parse_booleans\n",
        "\"Data files read\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "total_input_programs = length(groupby(exec_once, :input_program)) # Total number of input programs\n",
        "\n",
        "regular_success = nrow(filter([:platform, :completion_time] => (p, c) -> p === \"uninstrumented\" && c !== missing, exec_once))\n",
        "regular_timeout = nrow(filter([:platform, :timeout] => (p, t) -> p === \"uninstrumented\" && t, exec_once))\n",
        "regular_timeout_report = if regular_timeout == 0 begin \"\" end else \" ($regular_timeout timed out)\" end\n",
        "\n",
        "wasabi_success = nrow(filter([:platform, :completion_time] => (p, c) -> p === \"Wasabi\" && c !== missing, exec_once))\n",
        "wasabi_timeout = nrow(filter([:platform, :timeout] => (p, t) -> p === \"Wasabi\" && t, exec_once))\n",
        "wasabi_error_r = nrow(filter([:platform, :exception] => (p, e) -> p === \"Wasabi\" && e, exec_once))\n",
        "wasabi_unsuccesful_report = if wasabi_timeout == 0 && wasabi_error_r == 0 begin\n",
        "    \"\"\n",
        "end elseif wasabi_timeout == 0 && wasabi_error_r > 0 begin\n",
        "    \" ($wasabi_error_r errored)\"\n",
        "end elseif wasabi_timeout > 0 && wasabi_error_r == 0 begin\n",
        "    \" ($wasabi_timeout timed out)\"\n",
        "end else\n",
        "    \" ($wasabi_timeout timed out, $wasabi_error_r errored)\"\n",
        "end\n",
        "\n",
        "wastrm_success = nrow(filter([:platform, :completion_time] => (p, c) -> p === \"Wastrumentation\" && c !== missing, exec_once))\n",
        "wastrm_timeout = nrow(filter([:platform, :timeout] => (p, t) -> p === \"Wastrumentation\" && t, exec_once))\n",
        "wastrm_error_r = nrow(filter([:platform, :exception] => (p, e) -> p === \"Wastrumentation\" && e, exec_once))\n",
        "\n",
        "wastrm_timeout_report = if wastrm_timeout == 0 begin \"\" end else \" ($wastrm_timeout timed out)\" end\n",
        "\n",
        "conclusion = \"For the forward analysis on a total of $total_input_programs input programs,\n",
        " our benchmark harness succesfully executed $regular_success programs uninstrumented$regular_timeout_report,\n",
        " $wastrm_success after instrumentation by Wastrumentation$wastrm_timeout_report and\n",
        " $wasabi_success after instrumentation by Wasabi$wasabi_unsuccesful_report.\"\n",
        "\n",
        "println(conclusion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Memory Usage Study"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "exec_per_platform = groupby(exec_once, :platform)\n",
        "exec_once_wastrm = exec_per_platform[(\"Wastrumentation\",)]\n",
        "exec_once_wasabi = exec_per_platform[(\"Wasabi\",)]\n",
        "exec_once_rgular = exec_per_platform[(\"uninstrumented\",)]\n",
        "\n",
        "exec_once_baseline = rename(\n",
        "    select(exec_once_rgular, [:input_program, :memory_usage, :exception, :timeout]),\n",
        "    :memory_usage => :baseline_memory_usage,\n",
        "    :exception => :baseline_exception,\n",
        "    :timeout => :baseline_timeout,\n",
        ")\n",
        "\n",
        "wasabi_wastrm_mem_usage = vcat(exec_once_wastrm, exec_once_wasabi)\n",
        "wasabi_wastrm_mem_overhead = transform(\n",
        "    innerjoin(exec_once_baseline, wasabi_wastrm_mem_usage, on=[:input_program]),\n",
        "    [:baseline_memory_usage, :memory_usage] =>\n",
        "    ByRow((baseline_memory_usage, memory_usage) -> begin\n",
        "        if memory_usage === missing || baseline_memory_usage === missing\n",
        "            missing\n",
        "        else\n",
        "            memory_usage / baseline_memory_usage\n",
        "        end\n",
        "    end)\n",
        "    => :memory_usage_overhead,\n",
        ")\n",
        "\n",
        "\"Parsed memory data frames\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "wasabi_wastrm_mem_overhead_plot = wasabi_wastrm_mem_overhead |> @vlplot(\n",
        "  encoding={\n",
        "    x={\n",
        "      field=\"input_program\",\n",
        "      type=\"nominal\",\n",
        "      axis={\n",
        "        labelAngle=-30,\n",
        "        title=\"Input Program\",\n",
        "        labelFontSize=10,\n",
        "        titleFontSize=12,\n",
        "        titlePadding=10,\n",
        "      },\n",
        "    },\n",
        "    y={\n",
        "      field=\"memory_usage_overhead\",\n",
        "      type=\"quantitative\",\n",
        "      axis={\n",
        "        title=\"Runtime Memory Overhead (X)\",\n",
        "        titleFontSize=12,\n",
        "        labelFontSize=10,\n",
        "        grid=false,\n",
        "      },\n",
        "      scale={\n",
        "        type=\"log\",\n",
        "      },\n",
        "    },\n",
        "    color={\n",
        "      field=\"platform\",\n",
        "      type=\"nominal\",\n",
        "      scale={\n",
        "        scheme=\"pastel2\",\n",
        "      },\n",
        "      legend={\n",
        "        title=\"Instrumentation Platform\",\n",
        "        orient=\"top\",\n",
        "        titleFontSize=12,\n",
        "        labelFontSize=10,\n",
        "      },\n",
        "    },\n",
        "    xOffset={\n",
        "      field=\"platform\",\n",
        "      type=\"nominal\",\n",
        "    },\n",
        "    size={value=10},  # Adjusts the width of the bars\n",
        "  },\n",
        "  layer=[\n",
        "    {\n",
        "      mark={\n",
        "        type=\"bar\",\n",
        "        cornerRadiusEnd=3,\n",
        "      },\n",
        "    },\n",
        "    {\n",
        "      mark={\n",
        "        type=\"text\",\n",
        "        align=\"center\",\n",
        "        baseline=\"middle\",\n",
        "        angle=90,  # Rotates the labels vertically\n",
        "        fontSize=10,\n",
        "        dx=-15,  # Adjust horizontal offset to center labels over bars\n",
        "      },\n",
        "      encoding={\n",
        "        text={\n",
        "          field=\"memory_usage_overhead\",\n",
        "          type=\"quantitative\",\n",
        "          format=\".2f\",  # Adjust number format as needed\n",
        "        },\n",
        "      },\n",
        "    },\n",
        "  ],\n",
        "  title=\"Memory Overhead Comparison for Forward Analysis using Wasabi and Wastrumentation\",\n",
        "  config={\n",
        "    view={stroke=:transparent},\n",
        "    axis={\n",
        "      domainColor=\"#999\",\n",
        "    },\n",
        "  },\n",
        "  width=550,\n",
        "  height=100,\n",
        ")\n",
        "\n",
        "wasabi_wastrm_mem_overhead_plot |> save(target_dir_prefix * \"memory-overhead.pdf\")\n",
        "wasabi_wastrm_mem_overhead_plot\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Code Size Study"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_code_sizes = DataFrame(load(target_dir_prefix * \"code-sizes.csv\"))\n",
        "\"Data files read\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot Code Size Increase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "baseline_code_size = select(filter(row -> row.platform .== \"uninstrumented\", df_code_sizes), Not(:analysis, :platform))\n",
        "baseline_code_size_renamed = rename(baseline_code_size, :size_bytes => :size_bytes_baseline)\n",
        "\n",
        "code_size_inc_transformation = [:size_bytes, :size_bytes_baseline] => ((size_bytes, size_bytes_baseline) -> size_bytes ./ size_bytes_baseline) => :code_increase\n",
        "code_size_baseline_joined = leftjoin(\n",
        "    filter(row -> row.platform !== \"uninstrumented\", df_code_sizes),\n",
        "    baseline_code_size_renamed,\n",
        "    on=:input_program\n",
        ")\n",
        "\n",
        "code_size_overhead = transform(code_size_baseline_joined, code_size_inc_transformation)\n",
        "\"Relative code size increase computed\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "absolute_code_size_plot = baseline_code_size_renamed |> @vlplot(\n",
        "    encoding={\n",
        "        x={\n",
        "          field=\"input_program\",\n",
        "          type=\"nominal\",\n",
        "          axis={title=\"Input Program\",},\n",
        "          axis={labelAngle=\"-30\"},\n",
        "        },\n",
        "        y={\n",
        "            field=\"size_bytes_baseline\",\n",
        "            type=\"quantitative\",\n",
        "            axis={\n",
        "                title=\"Program Size (bytes)\",\n",
        "                grid=false,\n",
        "                titleFontSize=12,\n",
        "                labelFontSize=10,\n",
        "                labelColor=\"#666\",  # Softer axis label color\n",
        "                domainColor=\"#999\",  # Softer axis line color\n",
        "            },\n",
        "            scale={\n",
        "                type=\"log\",\n",
        "            },\n",
        "        },\n",
        "        color={\n",
        "            value=\"#4C72B0\",  # Soft blue color for bars\n",
        "        },\n",
        "    },\n",
        "    layer=[\n",
        "        {\n",
        "            mark={\n",
        "                type=\"bar\",\n",
        "                cornerRadiusEnd=3,  # Adds rounded corners to the top of bars\n",
        "            },\n",
        "        },\n",
        "        {\n",
        "            mark={\n",
        "                type=\"text\",\n",
        "                align=\"center\",\n",
        "                baseline=\"middle\",\n",
        "                fontSize=10,\n",
        "                dx=-27,\n",
        "            },\n",
        "            encoding={\n",
        "                text={\n",
        "                    field=\"size_bytes_baseline\",\n",
        "                    type=\"quantitative\",\n",
        "                    format=\",.0f\"\n",
        "                },\n",
        "                angle={\"value\"=90}\n",
        "            }\n",
        "        }\n",
        "    ],\n",
        "    config={\n",
        "        view={stroke=:transparent},\n",
        "    },\n",
        "    title=\"Absolute Code Size per Input Program\",  # Adds a descriptive title\n",
        "    width=550,\n",
        "    height=100,\n",
        ")\n",
        "absolute_code_size_plot |> save(target_dir_prefix * \"absolute-code-size-plot.pdf\")\n",
        "absolute_code_size_plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "code_incr_forward = filter(\n",
        "  :analysis => .==(\"forward\"),\n",
        "  filter(row -> row.analysis !== missing, code_size_overhead),\n",
        ")\n",
        "binary_size_plot = code_incr_forward |>\n",
        "@vlplot(\n",
        "  width=500,\n",
        "  layer=[\n",
        "    {\n",
        "      mark=\"bar\",\n",
        "      encoding={\n",
        "        color={\n",
        "          field=\"platform\",\n",
        "          type=\"nominal\",\n",
        "          legend={\n",
        "            title=\"Instrumentation Platform\",\n",
        "            orient=\"top\",\n",
        "          }\n",
        "        },\n",
        "        xOffset={\n",
        "          field=\"platform\",\n",
        "          type=\"nominal\",\n",
        "        },\n",
        "        x={\n",
        "          field=\"input_program\",\n",
        "          type=\"nominal\",\n",
        "          axis={labelAngle=\"45\"},\n",
        "          title=\"Input Program\",\n",
        "        },\n",
        "        y={\n",
        "          field=\"code_increase\",\n",
        "          type=\"quantitative\",\n",
        "          axis={\n",
        "            title=\"Program Size Increase (X)\",\n",
        "            grid=false,\n",
        "          },\n",
        "        },\n",
        "      },\n",
        "    },\n",
        "    {\n",
        "      mark=\"rule\",\n",
        "      encoding={\n",
        "        y={\n",
        "          datum=1,\n",
        "        },\n",
        "        color={value=\"red\"}, # Color for the line\n",
        "        size={value=1} # Thickness of the line\n",
        "      },\n",
        "    },\n",
        "  ],\n",
        "  config={\n",
        "    view={stroke=:transparent},\n",
        "  },\n",
        ")\n",
        "\n",
        "binary_size_plot |> save(target_dir_prefix * \"wasabi-wastrm-binary-size.pdf\")\n",
        "binary_size_plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_code_sizes_plot = code_size_overhead |> @vlplot(\n",
        "  \"transform\"=[\n",
        "    {\n",
        "      \"calculate\"=\"substring(datum.code_increase, 0, 5)\",\n",
        "      \"as\"=\"code_increase_truncated\"\n",
        "    },\n",
        "  ],\n",
        "  facet={\n",
        "    row={\n",
        "      field=\"platform\",\n",
        "      type=\"nominal\",\n",
        "    },\n",
        "  },\n",
        "  spec={\n",
        "    layer=[\n",
        "      {\n",
        "        mark=\"rect\",encoding={\n",
        "          y={\n",
        "            field=\"analysis\",\n",
        "            type=\"nominal\",\n",
        "            axis={labelAngle=\"-30\"},\n",
        "          },\n",
        "          x={\n",
        "            field=\"input_program\",\n",
        "            type=\"nominal\",\n",
        "            axis={title=\"Input Program\",},\n",
        "            axis={labelAngle=\"-30\"},\n",
        "          },\n",
        "          color={\n",
        "          field=\"code_increase\",\n",
        "          type=\"quantitative\",\n",
        "          scale={\n",
        "            type=\"log\",\n",
        "            scheme=\"blues\",\n",
        "          },\n",
        "          legend={\n",
        "            title=\"Code Size Increase (X)\",\n",
        "            orient=\"top\",\n",
        "            titleLimit=1000,\n",
        "            gradientLength=540,\n",
        "            titleAnchor=\"center\",\n",
        "            titleAlign=\"center\",\n",
        "          },\n",
        "        },\n",
        "        },\n",
        "        \n",
        "      },\n",
        "      {\n",
        "        mark={\n",
        "          type=\"text\",\n",
        "          fontSize=\"6\",\n",
        "        },\n",
        "        encoding={\n",
        "          y={\n",
        "            field=\"analysis\",\n",
        "            type=\"nominal\",\n",
        "          },\n",
        "          x={\n",
        "            field=\"input_program\",\n",
        "            type=\"nominal\",\n",
        "            axis={title=\"Input Program\",},\n",
        "          },\n",
        "          text={\n",
        "            field=\"code_increase_truncated\",\n",
        "            type=\"quantitative\",\n",
        "          },\n",
        "        },\n",
        "      },\n",
        "    ],\n",
        "\n",
        "  },\n",
        "  config={\n",
        "    axis={\n",
        "      grid=true,\n",
        "      tickBand=\"extent\",\n",
        "    },\n",
        "  },\n",
        ")\n",
        "\n",
        "all_code_sizes_plot |> save(target_dir_prefix * \"wasabi-wastrm-binary-size.pdf\")\n",
        "all_code_sizes_plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "wasabi_code_size = select(filter(row -> row.platform .== \"Wasabi\", df_code_sizes), Not(:platform))\n",
        "wastrm_code_size = select(filter(row -> row.platform .== \"Wastrumentation\", df_code_sizes), Not(:platform))\n",
        "\"Absolute code sizes computed\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "wasabi_wastrm_size_overhead = transform(\n",
        "  outerjoin(\n",
        "    rename(wasabi_code_size, :size_bytes => :wasabi_size_bytes),\n",
        "    rename(wastrm_code_size, :size_bytes => :wastrm_size_bytes),\n",
        "    on=[:analysis, :input_program],\n",
        "  ),\n",
        "  [:wasabi_size_bytes, :wastrm_size_bytes]\n",
        "    => ((wasabi_size_bytes, wastrm_size_bytes) -> wasabi_size_bytes ./ wastrm_size_bytes)\n",
        "    => :code_size_for_wasabi_over_wastrm,\n",
        ")\n",
        "\"Relative code size overhead computed\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @assert length(groupby(wastrm_code_size, :input_program)) == 27\n",
        "length(groupby(wastrm_code_size, :input_program)) # FIXME: ???"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "code_size_for_wasabi_per_time_for_wastrm_non_missing = filter(row -> row.code_size_for_wasabi_over_wastrm !== missing, wasabi_wastrm_size_overhead)\n",
        "total_outout_cpmr_progms = nrow(code_size_for_wasabi_per_time_for_wastrm_non_missing)\n",
        "wastrm_output_is_smaller = filter(row -> row.code_size_for_wasabi_over_wastrm > 1, code_size_for_wasabi_per_time_for_wastrm_non_missing)\n",
        "wasabi_output_is_smaller = filter(row -> row.code_size_for_wasabi_over_wastrm < 1, code_size_for_wasabi_per_time_for_wastrm_non_missing)\n",
        "wastrm_wasabi_equal_size = filter(row -> row.code_size_for_wasabi_over_wastrm === 1, code_size_for_wasabi_per_time_for_wastrm_non_missing)\n",
        "\n",
        "\n",
        "sentence = \"For a total of $total_outout_cpmr_progms output programs, $(nrow(wastrm_output_is_smaller)) have a smaller output size for Wastrumentation and $(nrow(wasabi_output_is_smaller)) have a smaller output size for Wasabi.\"\n",
        "sentence\n",
        "# mean(code_size_for_wasabi_per_time_for_wastrm_non_missing.code_size_for_wasabi_over_wastrm)\n",
        "# std(code_size_for_wasabi_per_time_for_wastrm_non_missing.code_size_for_wasabi_over_wastrm, corrected=false)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# transform(wasabi_wastrm_size_overhead,\n",
        "#   [:code_size_for_wasabi_over_wastrm] => ByRow((r) -> if r == )\n",
        "# )\n",
        "skipmissing(wasabi_wastrm_size_overhead)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "binary_size_overhead_comparison_plot = wasabi_wastrm_size_overhead |>\n",
        "@vlplot(\n",
        "  \"transform\"=[\n",
        "    {\n",
        "      # Calculate truncated value and replace null with an empty string\n",
        "      \"calculate\"=\"datum.code_size_for_wasabi_over_wastrm == null ? '' : substring(datum.code_size_for_wasabi_over_wastrm, 0, 5)\",\n",
        "      \"as\"=\"relative_overhead_truncated\"\n",
        "    },\n",
        "  ],\n",
        "  encoding={\n",
        "    y={\n",
        "      field=\"analysis\",\n",
        "      type=\"nominal\",\n",
        "      axis={labelAngle=\"-30\"},\n",
        "    },\n",
        "    x={\n",
        "      field=\"input_program\",\n",
        "      type=\"nominal\",\n",
        "      axis={title=\"Input Program\",labelAngle=\"-30\"},\n",
        "    },\n",
        "  },\n",
        "  layer=[\n",
        "    {\n",
        "      mark=\"rect\",\n",
        "      encoding={\n",
        "        color={\n",
        "          field=\"code_size_for_wasabi_over_wastrm\",\n",
        "          type=\"quantitative\",\n",
        "          scale={\n",
        "            domainMid=1,\n",
        "            scheme=\"redyellowgreen\",\n",
        "            type=\"log\",\n",
        "          },\n",
        "          legend={\n",
        "            title=\"Wasabi Output Code Size / Wastrumentation Output Code Size\",\n",
        "            orient=\"top\",\n",
        "            titleLimit=1000,\n",
        "            gradientLength=540,\n",
        "            titleAnchor=\"center\",\n",
        "            titleAlign=\"center\",\n",
        "          }\n",
        "        },\n",
        "      },\n",
        "    },\n",
        "    {\n",
        "      mark={\n",
        "        type=\"text\",\n",
        "        fontSize=\"6\",\n",
        "      },\n",
        "      encoding={\n",
        "        text={\n",
        "          field=\"relative_overhead_truncated\",\n",
        "          type=\"nominal\",\n",
        "        },\n",
        "      },\n",
        "    },\n",
        "  ],\n",
        "  config={\n",
        "    axis={grid=true, tickBand=\"extent\",}\n",
        "  },\n",
        ")\n",
        "\n",
        "binary_size_overhead_comparison_plot |> save(target_dir_prefix * \"wastrumentation-wasabi-size-overhead-comparison.pdf\")\n",
        "binary_size_overhead_comparison_plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot Engine Warmup Over Time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# String   : runtime\n",
        "# String   : platform\n",
        "# String   : analysis\n",
        "# String   : input_program\n",
        "# Int64?   : memory_usage\n",
        "# Float64? : completion_time\n",
        "# Int64    : runtime_iteration\n",
        "# \"ms\"     : time_unit\n",
        "# Bool     : exception\n",
        "# String?  : exception_reason\n",
        "# Bool     : timeout\n",
        "# Int64    : timeout_amount\n",
        "\n",
        "function parse_boolean(df, column)\n",
        "  return transform(df, column => ByRow(parse_boolean) => column)\n",
        "end\n",
        "\n",
        "runtime_performance = DataFrame(load(target_dir_prefix * \"executes-bench.csv\"))\n",
        "runtime_performance = parse_boolean(runtime_performance, :exception)\n",
        "runtime_performance = parse_boolean(runtime_performance, :timeout)\n",
        "runtime_performance\n",
        "\n",
        "df_rgular = select(filter(row -> row.platform .== \"uninstrumented\",  runtime_performance), Not([:platform, :analysis]))\n",
        "df_wasabi = select(filter(row -> row.platform .== \"Wasabi\",          runtime_performance), Not(:platform))\n",
        "df_wastrm = select(filter(row -> row.platform .== \"Wastrumentation\", runtime_performance), Not(:platform))\n",
        "\n",
        "# Squash together inter-runtime iterations => [1, 2, 3, 1, 2, 3] => [1, 2, 3]\n",
        "\n",
        "function squash_inter_runtime_iterations(df)\n",
        "  combine(\n",
        "      groupby(df, Cols(:input_program, :runtime, :runtime_iteration, :platform, :analysis)),\n",
        "      # :performance::Vec{Float64}, :error::Vec{Bool}, :timeout::Vec{Bool}\n",
        "      [:performance, :error, :timeout] =>\n",
        "      # combine rows such that:\n",
        "      #   if any row has error, the combination is error\n",
        "      #   if none are error, but any row is timeout, the combination is timeout\n",
        "      #   none should be error or timeout, the combination is the median\n",
        "      ((perf, err, to) -> if any(Bool.(err))\n",
        "          (; performance = missing, error = true, timeout = false)  # Return NamedTuple\n",
        "      elseif any(Bool.(to))\n",
        "          (; performance = missing, error = false, timeout = true)  # Return NamedTuple\n",
        "      else\n",
        "          (; performance = median(perf), error = false, timeout = false)  # Return NamedTuple\n",
        "      end)\n",
        "      => [:performance, :error, :timeout],\n",
        "  )\n",
        "end\n",
        "\n",
        "# Expected to be the same:\n",
        "# `runtime`, `platform`, `analysis`, `input_program`\n",
        "# May differ:\n",
        "# `memory_usage`, `completion_time`, `time_unit`, `exception`, `exception_reason`, `timeout`, `timeout_amount`\n",
        "# Must differ: \n",
        "# `runtime_iteration`\n",
        "squash_query = Cols(:runtime, :platform, :analysis, :input_program)\n",
        "runtime_performance_aggregated = combine(groupby(runtime_performance, squash_query),\n",
        "  # :performance::Vec{Float64}, :error::Vec{Bool}, :timeout::Vec{Bool}\n",
        "  [:completion_time, :exception, :exception_reason, :timeout, :timeout_amount] =>\n",
        "  # combine rows such that:\n",
        "  ((completion_time, exception, exception_reason, timeout, timeout_amount) ->\n",
        "  if any(Bool.(exception)) # if any row has an error, the combination is considered an error\n",
        "    (; completion_time =                 missing, exception =  true, exception_reason = first(skipmissing(exception_reason)), timeout = false, timeout_amount = first(skipmissing(timeout_amount)))\n",
        "  elseif any(Bool.(timeout)) # if none are error, but any row is timeout, the combination is considered to timeout\n",
        "    (; completion_time =                 missing, exception = false, exception_reason =                              missing, timeout =  true, timeout_amount =      maximum(skipmissing(timeout)))\n",
        "  else # none should be error or timeout, the combination is considered the median\n",
        "    (; completion_time = median(completion_time), exception = false, exception_reason =                              missing, timeout = false, timeout_amount = first(skipmissing(timeout_amount)))\n",
        "  end)\n",
        "  # the returned named tuple is used as the combination outcome\n",
        "  =>\n",
        "  [:completion_time, :exception, :exception_reason, :timeout, :timeout_amount],\n",
        ")\n",
        "\n",
        "\n",
        "df_rgular_aggregated = select(filter(row -> row.platform .== \"uninstrumented\",  runtime_performance_aggregated), Not([:platform, :analysis]))\n",
        "df_wasabi_aggregated = select(filter(row -> row.platform .== \"Wasabi\",          runtime_performance_aggregated), Not(:platform))\n",
        "df_wastrm_aggregated = select(filter(row -> row.platform .== \"Wastrumentation\", runtime_performance_aggregated), Not(:platform))\n",
        "\"parsed & squased runtime performance\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if length(unique(df_rgular.runtime_iteration)) > 1\n",
        "  df_rgular |>\n",
        "  @vlplot(\n",
        "    :line,\n",
        "    encoding={\n",
        "      x={\n",
        "        field=\"runtime_iteration\",\n",
        "        type=\"nominal\",\n",
        "      },\n",
        "      y={\n",
        "        aggregate=\"median\",\n",
        "        field=\"completion_time\",\n",
        "        type=\"quantitative\",\n",
        "        scale={\n",
        "          type=\"log\"\n",
        "        },\n",
        "        title=\"Execution time (ms)\",\n",
        "      },\n",
        "      color={\n",
        "        field=\"input_program\",\n",
        "        type=\"nominal\",\n",
        "      },\n",
        "    },\n",
        "    config={\n",
        "      line={\n",
        "        point=true\n",
        "      },\n",
        "      scale={\n",
        "        useUnaggregatedDomain=true\n",
        "      },\n",
        "    },\n",
        "  )\n",
        "else\n",
        "  \"Cannot plot evolution of iterations over a single iteration ...\"\n",
        "end\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "filter(row -> row.analysis == \"forward\", df_wasabi) |>\n",
        "@vlplot(\n",
        "  :line,\n",
        "  mark={\n",
        "      :errorband,\n",
        "      extent=:ci,\n",
        "  },\n",
        "  encoding={\n",
        "    x={\n",
        "      field=\"runtime_iteration\",\n",
        "      type=\"nominal\",\n",
        "      scale={\n",
        "        \"rangeStep\"=12\n",
        "      },\n",
        "    },\n",
        "    y={\n",
        "      aggregate=\"median\",\n",
        "      field=\"completion_time\",\n",
        "      type=\"quantitative\",\n",
        "      scale={\n",
        "        type=\"log\"\n",
        "      },\n",
        "      title=\"Execution time (ms)\",\n",
        "    },\n",
        "    color={\n",
        "      field=\"input_program\",\n",
        "      type=\"nominal\",\n",
        "    },\n",
        "  },\n",
        "  config={\n",
        "    line={\n",
        "      point=true\n",
        "    },\n",
        "    scale={\n",
        "      useUnaggregatedDomain=true\n",
        "    },\n",
        "  },\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "filter(row -> row.analysis == \"forward\", df_wastrm) |>\n",
        "@vlplot(\n",
        "  :line,\n",
        "  mark={\n",
        "      :errorband,\n",
        "      extent=:ci,\n",
        "  },\n",
        "  encoding={\n",
        "    x={\n",
        "      field=\"runtime_iteration\",\n",
        "      type=\"nominal\",\n",
        "      scale={\n",
        "        \"rangeStep\"=12\n",
        "      },\n",
        "    },\n",
        "    y={\n",
        "      aggregate=\"median\",\n",
        "      field=\"completion_time\",\n",
        "      type=\"quantitative\",\n",
        "      scale={\n",
        "        type=\"log\"\n",
        "      },\n",
        "      title=\"Execution time (ms)\",\n",
        "    },\n",
        "    color={\n",
        "      field=\"input_program\",\n",
        "      type=\"nominal\",\n",
        "    },\n",
        "  },\n",
        "  config={\n",
        "    line={\n",
        "      point=true\n",
        "    },\n",
        "    scale={\n",
        "      useUnaggregatedDomain=true\n",
        "    },\n",
        "  },\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot Runtime Performances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_rgular_median_over_iterations = combine(groupby(df_rgular, Cols(:input_program, :runtime, :setup)), :performance => median => :performance)\n",
        "# df_wasabi_median_over_iterations = combine(groupby(df_wasabi, Cols(:input_program, :runtime, :platform, :analysis)), :performance => median => :performance)\n",
        "# df_wastrm_median_over_iterations = combine(groupby(df_wastrm, Cols(:input_program, :runtime, :platform, :analysis)), :performance => median => :performance)\n",
        "\n",
        "# function squash_iterations(df)\n",
        "#   combine(\n",
        "#     groupby(df, Cols(:input_program, :runtime, :platform, :analysis)),\n",
        "#     # :performance::Vec{Float64}, :error::Vec{Bool}, :timeout::Vec{Bool}\n",
        "#     [:performance, :error, :timeout] =>\n",
        "#     # combine rows such that:\n",
        "#     #   if any row has error, the combination is error\n",
        "#     #   if none are error, but any row is timeout, the combination is timeout\n",
        "#     #   none should be error or timeout, the combination is the median\n",
        "#     ((perf, err, to) -> if any(Bool.(err))\n",
        "#         (; performance = missing, error = true, timeout = false)  # Return NamedTuple\n",
        "#     elseif any(Bool.(to))\n",
        "#         (; performance = missing, error = false, timeout = true)  # Return NamedTuple\n",
        "#     else\n",
        "#         (; performance = median(perf), error = false, timeout = false)  # Return NamedTuple\n",
        "#     end)\n",
        "#     => [:performance, :error, :timeout],\n",
        "#   )\n",
        "# end\n",
        "\n",
        "# df_rgular_median_over_iterations = combine(groupby(df_rgular, Cols(:input_program, :runtime, :setup)), :performance => median => :performance)\n",
        "# df_wasabi_median_over_iterations = df_wasabi |> squash_iterations\n",
        "# df_wastrm_median_over_iterations = df_wastrm |> squash_iterations\n",
        "# \"Median over runtimes computed!\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# E.g. overhead wasabi: 10x\n",
        "#      overhead wastrm: 50x\n",
        "#\n",
        "#      ==> wasabi faster (lower overhead; 10 <= 50)\n",
        "#\n",
        "#      ==> wasabi / wastrm = 0.2\n",
        "#      ==> marked as \"1. wasabi is much faster\"\n",
        "\n",
        "performance_ordinal_domain = [\n",
        "  \"1. Wastrmnt >3 times slower\",\n",
        "  \"2. Wastrmnt 3-1.05 times slower\",\n",
        "  \"3. Wastrmnt comparable\",\n",
        "  \"4. Wastrmnt 3-1.05 times faster\",\n",
        "  \"5. Wastrmnt >3 times faster\",\n",
        "]\n",
        "\n",
        "#        1      \n",
        "# [-\u221e ======= 0.3 ======= 0.95 ======= 1.05 ======= 3 ======= 100 ======= ]\n",
        "function performance_comparison(n::Float64)\n",
        "    if n >= 0 && n <= 0.3\n",
        "        return performance_ordinal_domain[1]\n",
        "    elseif n > 0.3 && n <= 0.95\n",
        "        return performance_ordinal_domain[2]\n",
        "    elseif n > 0.95 && n <= 1.05\n",
        "        return performance_ordinal_domain[3]\n",
        "    elseif n > 1.05 && n <= 3\n",
        "        return performance_ordinal_domain[4]\n",
        "    elseif n > 3 && n < 100\n",
        "        return performance_ordinal_domain[5]\n",
        "    elseif n >= 100\n",
        "        return \"0. \u274c wasabi is INCREADIBLY SLOW\"\n",
        "    else\n",
        "        return \"Input is out of range\"\n",
        "    end\n",
        "  end\n",
        "\n",
        "function performance_comparison(n::Missing)\n",
        "    n\n",
        "  end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_wastrm_joined_rgular = innerjoin(\n",
        "  rename(df_rgular_aggregated, :completion_time  => :rgular_completion_time,\n",
        "                               :exception        => :rgular_exception,\n",
        "                               :exception_reason => :rgular_exception_reason,\n",
        "                               :timeout          => :rgular_timeout,\n",
        "                               :timeout_amount   => :rgular_timeout_amount),\n",
        "  rename(df_wastrm_aggregated, :completion_time  => :wastrm_completion_time,\n",
        "                               :exception        => :wastrm_exception,\n",
        "                               :exception_reason => :wastrm_exception_reason,\n",
        "                               :timeout          => :wastrm_timeout,\n",
        "                               :timeout_amount   => :wastrm_timeout_amount),\n",
        "  on=[:runtime, :input_program],\n",
        ")\n",
        "\"joined\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_wasabi_joined_rgular = innerjoin(\n",
        "  rename(df_rgular_aggregated, :completion_time  => :rgular_completion_time,\n",
        "                               :exception        => :rgular_exception,\n",
        "                               :exception_reason => :rgular_exception_reason,\n",
        "                               :timeout          => :rgular_timeout,\n",
        "                               :timeout_amount   => :rgular_timeout_amount),\n",
        "  rename(df_wasabi_aggregated, :completion_time  => :wasabi_completion_time,\n",
        "                               :exception        => :wasabi_exception,\n",
        "                               :exception_reason => :wasabi_exception_reason,\n",
        "                               :timeout          => :wasabi_timeout,\n",
        "                               :timeout_amount   => :wasabi_timeout_amount),\n",
        "  on=[:runtime, :input_program],\n",
        ")\n",
        "\"joined\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_wastrm_instruction_overhead_labeled = transform(\n",
        "#   outerjoin(\n",
        "#     select(rename(df_rgular_aggregated, :performance => :rgular_performance), Not([:setup])),\n",
        "#     select(rename(df_wastrm_aggregated, :performance => :wastrm_performance), Not([:platform])),\n",
        "#     on=[:runtime, :input_program],\n",
        "#   ),\n",
        "#   [:rgular_performance, :wastrm_performance, :error, :timeout] =>\n",
        "#   ByRow((rgular_performance, wastrm_performance, err, timeout) -> \n",
        "#   begin\n",
        "#     @assert !(rgular_performance === missing)\n",
        "#     @assert !(wastrm_performance === missing && err === missing && timeout === missing)\n",
        "#     if err\n",
        "#         [missing, \"E\"]\n",
        "#     elseif timeout\n",
        "#       [missing, \"T\"]\n",
        "#     else\n",
        "#       relative_performance = wastrm_performance / rgular_performance\n",
        "#       [relative_performance, @sprintf(\"%.4g\", relative_performance)]\n",
        "#     end\n",
        "#   end)\n",
        "#   => [:overhead, :text_report]\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_wasabi_instruction_overhead = select(\n",
        "#   rightjoin(rename(select(df_rgular, :input_program, :performance, :runtime_iteration), :performance => :performance_baseline), df_wasabi, on=[:runtime_iteration, :input_program]),\n",
        "#   [:performance, :performance_baseline]\n",
        "#     => ((performance, performance_baseline) -> performance ./ performance_baseline)\n",
        "#     => :overhead,\n",
        "#   # What to keep:\n",
        "#   :input_program, :runtime_iteration, :runtime, :platform, :analysis\n",
        "# )\n",
        "\n",
        "# df_wastrm_instruction_overhead = select(\n",
        "#   rightjoin(rename(select(df_rgular, :input_program, :performance, :runtime_iteration), :performance => :performance_baseline), df_wastrm, on=[:runtime_iteration, :input_program]),\n",
        "#   [:performance, :performance_baseline]\n",
        "#     => ((performance, performance_baseline) -> performance ./ performance_baseline)\n",
        "#     => :overhead,\n",
        "#   # What to keep:\n",
        "#   :input_program, :runtime_iteration, :runtime, :platform, :analysis\n",
        "# )\n",
        "\n",
        "# \"Overheads computed!\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Aggregate all overhead\n",
        "# df_wasabi_instruction_overhead_single = combine(groupby(df_wasabi_instruction_overhead, Cols(:input_program, :runtime, :platform, :analysis)), :overhead => median => :overhead)\n",
        "# df_wastrm_instruction_overhead_single = combine(groupby(df_wastrm_instruction_overhead, Cols(:input_program, :runtime, :platform, :analysis)), :overhead => median => :overhead)\n",
        "# \"Aggregated!\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_wasabi_instruction_overhead_single = transform(\n",
        "    df_wasabi_joined_rgular,\n",
        "    [:rgular_completion_time, :wasabi_completion_time, :wasabi_exception, :wasabi_exception_reason, :wasabi_timeout]\n",
        "    =>\n",
        "    ByRow((rgular_completion_time, wasabi_completion_time, wasabi_exception, wasabi_exception_reason, wasabi_timeout) -> begin\n",
        "        @assert !(rgular_completion_time === missing)\n",
        "        if wasabi_timeout       return (\"Wasabi\", missing, \"T\")\n",
        "        elseif wasabi_exception return (\"Wasabi\", missing, \"MD\")\n",
        "        else                    return (\"Wasabi\", wasabi_completion_time / rgular_completion_time, wasabi_completion_time / rgular_completion_time)\n",
        "        end\n",
        "    end)\n",
        "    =>\n",
        "    [:platform, :overhead, :text_report],\n",
        ")\n",
        "\"wasabi_overhead_plot computed!\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_wastrm_instruction_overhead_single = transform(\n",
        "    df_wastrm_joined_rgular,\n",
        "    [:rgular_completion_time, :wastrm_completion_time, :wastrm_exception, :wastrm_exception_reason, :wastrm_timeout]\n",
        "    =>\n",
        "    ByRow((rgular_completion_time, wastrm_completion_time, wastrm_exception, wastrm_exception_reason, wastrm_timeout) -> begin\n",
        "        @assert !(rgular_completion_time === missing)\n",
        "        if wastrm_timeout       return (\"Wastrumentation\", missing, \"T\")\n",
        "        elseif wastrm_exception return (\"Wastrumentation\", missing, \"MD\")\n",
        "        else                    return (\"Wastrumentation\", wastrm_completion_time / rgular_completion_time, wastrm_completion_time / rgular_completion_time)\n",
        "        end\n",
        "    end)\n",
        "    =>\n",
        "    [:platform, :overhead, :text_report],\n",
        ")\n",
        "\"wastrm_overhead_plot computed!\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "wasabi_overhead_plot = df_wasabi_instruction_overhead_single |>\n",
        "@vlplot(\n",
        "  \"transform\"=[\n",
        "    {\n",
        "      \"calculate\"=\"substring(datum.text_report, 0, 5)\",\n",
        "      \"as\"=\"overhead_truncated\"\n",
        "    },\n",
        "  ],\n",
        "  encoding={\n",
        "    y={\n",
        "      field=\"analysis\",\n",
        "      type=\"nominal\",\n",
        "    },\n",
        "    x={\n",
        "      field=\"input_program\",\n",
        "      type=\"nominal\",\n",
        "      axis={title=\"Input Program\",},\n",
        "    },\n",
        "  },\n",
        "  layer=[\n",
        "    {\n",
        "      mark=\"rect\",\n",
        "      encoding={\n",
        "        color={\n",
        "          field=\"overhead\",\n",
        "          type=\"quantitative\",\n",
        "          scale={\n",
        "            type=\"log\",\n",
        "            scheme=\"blues\",\n",
        "          },\n",
        "          legend={\n",
        "            title=\"Overhead for Wasabi\",\n",
        "            orient=\"top\",\n",
        "            titleLimit=1000,\n",
        "            gradientLength=400,\n",
        "            titleAnchor=\"center\",\n",
        "            titleAlign=\"center\",\n",
        "          }\n",
        "        },\n",
        "      },\n",
        "    },\n",
        "    {\n",
        "      mark={\n",
        "        type=\"text\",\n",
        "        fontSize=\"6\",\n",
        "      },\n",
        "      encoding={\n",
        "        text={\n",
        "          field=\"overhead_truncated\",\n",
        "          type=\"nominal\",\n",
        "        },\n",
        "      },\n",
        "    },\n",
        "  ],\n",
        "  config={\n",
        "    axis={grid=true, tickBand=\"extent\",}\n",
        "  },\n",
        ")\n",
        "\n",
        "wasabi_overhead_plot |> save(target_dir_prefix * \"wasabi-overhead.pdf\")\n",
        "wasabi_overhead_plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "wastrm_overhead_plot_single = df_wastrm_instruction_overhead_single |>\n",
        "@vlplot(\n",
        "  \"transform\"=[\n",
        "    {\n",
        "      \"calculate\"=\"substring(datum.text_report, 0, 5)\",\n",
        "      \"as\"=\"text_report_truncated\"\n",
        "    },\n",
        "  ],\n",
        "  encoding={\n",
        "    y={\n",
        "      field=\"analysis\",\n",
        "      type=\"nominal\",\n",
        "      axis={labelAngle=\"-30\"},\n",
        "    },\n",
        "    x={\n",
        "      field=\"input_program\",\n",
        "      type=\"nominal\",\n",
        "      axis={labelAngle=\"-30\",title=\"Input Program\",},\n",
        "    },\n",
        "  },\n",
        "  layer=[\n",
        "    {\n",
        "      mark=\"rect\",\n",
        "      encoding={\n",
        "        color={\n",
        "          field=\"overhead\",\n",
        "          type=\"quantitative\",\n",
        "          scale={\n",
        "            type=\"log\",\n",
        "            scheme=\"blues\",\n",
        "          },\n",
        "          legend={\n",
        "            title=\"Overhead for Wastrumentation\",\n",
        "            orient=\"top\",\n",
        "            titleLimit=1000,\n",
        "            gradientLength=540,\n",
        "            titleAnchor=\"center\",\n",
        "            titleAlign=\"center\",\n",
        "          }\n",
        "        },\n",
        "      },\n",
        "    },\n",
        "    {\n",
        "      mark={\n",
        "        type=\"text\",\n",
        "        fontSize=\"6\",\n",
        "      },\n",
        "      encoding={\n",
        "        text={\n",
        "          field=\"text_report_truncated\",\n",
        "          type=\"nominal\",\n",
        "        },\n",
        "      },\n",
        "    },\n",
        "  ],\n",
        "  config={\n",
        "    axis={grid=true, tickBand=\"extent\",}\n",
        "  },\n",
        ")\n",
        "\n",
        "\n",
        "wastrm_overhead_plot_single |> save(target_dir_prefix * \"wastrumentation-runtime-overhead-plot-single.pdf\")\n",
        "wastrm_overhead_plot_single"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "wastrm_overhead_plot = df_wastrm_instruction_overhead_single |>\n",
        "@vlplot(\n",
        "  \"transform\"=[\n",
        "    {\n",
        "      \"calculate\"=\"substring(datum.text_report, 0, 5)\",\n",
        "      \"as\"=\"text_report_truncated\"\n",
        "    },\n",
        "  ],\n",
        "  \"spacing\"=15,\n",
        "  \"bounds\"=\"flush\",\n",
        "  \"vconcat\"=[\n",
        "    {\n",
        "      \"mark\"={\n",
        "        \"type\"=\"boxplot\",\n",
        "        \"extent\"=\"min-max\",\n",
        "      },\n",
        "      \"height\"=100,\n",
        "      \"encoding\"={\n",
        "        \"x\"={\n",
        "          field=\"input_program\",\n",
        "          type=\"nominal\",\n",
        "          \"axis\"=false\n",
        "        },\n",
        "        \"y\"={\n",
        "          field=\"overhead\",\n",
        "          type=\"quantitative\",\n",
        "          \"scale\"={type=\"log\", domainMin=1,},\n",
        "          \"title\"=\"\",\n",
        "        },\n",
        "      },\n",
        "    },\n",
        "    {\n",
        "      \"spacing\"=15,\n",
        "      \"bounds\"=\"flush\",\n",
        "      \"hconcat\"=[\n",
        "        {\n",
        "          encoding={\n",
        "            y={\n",
        "              field=\"analysis\",\n",
        "              type=\"nominal\",\n",
        "              axis={labelAngle=\"-30\"},\n",
        "            },\n",
        "            x={\n",
        "              field=\"input_program\",\n",
        "              type=\"nominal\",\n",
        "              axis={title=\"Input Program\",labelAngle=\"-30\"},\n",
        "            },\n",
        "          },\n",
        "          layer=[\n",
        "            {\n",
        "              mark=\"rect\",\n",
        "              encoding={\n",
        "                color={\n",
        "                  field=\"overhead\",\n",
        "                  type=\"quantitative\",\n",
        "                  scale={\n",
        "                    type=\"log\",\n",
        "                    scheme=\"blues\",\n",
        "                  },\n",
        "                  legend={\n",
        "                    title=\"Overhead for Wastrumentation\",\n",
        "                    orient=\"top\",\n",
        "                    titleLimit=1000,\n",
        "                    gradientLength=540,\n",
        "                    titleAnchor=\"center\",\n",
        "                    titleAlign=\"center\",\n",
        "                  }\n",
        "                },\n",
        "              },\n",
        "            },\n",
        "            {\n",
        "              mark={\n",
        "                type=\"text\",\n",
        "                fontSize=\"6\",\n",
        "              },\n",
        "              encoding={\n",
        "                text={\n",
        "                  field=\"text_report_truncated\",\n",
        "                  type=\"nominal\",\n",
        "                },\n",
        "              },\n",
        "            },\n",
        "          ],\n",
        "        },\n",
        "        {\n",
        "          \"mark\"={\n",
        "            \"type\"=\"boxplot\",\n",
        "            \"extent\"=\"min-max\",\n",
        "          },\n",
        "          \"width\"=100,\n",
        "          \"encoding\"={\n",
        "            \"y\"={\n",
        "              field=\"analysis\",\n",
        "              type=\"nominal\",\n",
        "              \"axis\"=false\n",
        "            },\n",
        "            \"x\"={\n",
        "              field=\"overhead\",\n",
        "              type=\"quantitative\",\n",
        "              \"scale\"={type=\"log\", domainMin=1,},\n",
        "              \"title\"=\"\",\n",
        "            }\n",
        "          }\n",
        "        },\n",
        "      ]\n",
        "    }\n",
        "  ],\n",
        "  config={\n",
        "    axis={grid=true, tickBand=\"extent\",}\n",
        "  },\n",
        ")\n",
        "\n",
        "wastrm_overhead_plot |> save(target_dir_prefix * \"wastrumentation-runtime-overhead-plot.pdf\")\n",
        "wastrm_overhead_plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_performance_overhead = vcat(\n",
        "  select(df_wastrm_instruction_overhead_single, Not([:wastrm_completion_time, :wastrm_exception, :wastrm_exception_reason, :wastrm_timeout, :wastrm_timeout_amount])),\n",
        "  select(df_wasabi_instruction_overhead_single, Not([:wasabi_completion_time, :wasabi_exception, :wasabi_exception_reason, :wasabi_timeout, :wasabi_timeout_amount])),\n",
        ")\n",
        "\n",
        "all_performance_overhead_plot = all_performance_overhead |> @vlplot(\n",
        "  \"transform\"=[\n",
        "    {\n",
        "      \"calculate\"=\"substring(datum.text_report, 0, 5)\",\n",
        "      \"as\"=\"text_report_truncated\"\n",
        "    },\n",
        "  ],\n",
        "  facet={\n",
        "    row={\n",
        "      field=\"platform\",\n",
        "      type=\"nominal\",\n",
        "    },\n",
        "  },\n",
        "  spec={\n",
        "    layer=[\n",
        "      {\n",
        "        mark=\"rect\",encoding={\n",
        "          y={\n",
        "            field=\"analysis\",\n",
        "            type=\"nominal\",\n",
        "            axis={labelAngle=\"-30\"},\n",
        "          },\n",
        "          x={\n",
        "            field=\"input_program\",\n",
        "            type=\"nominal\",\n",
        "            axis={title=\"Input Program\",},\n",
        "            axis={labelAngle=\"-30\"},\n",
        "          },\n",
        "          color={\n",
        "          field=\"overhead\",\n",
        "          type=\"quantitative\",\n",
        "          scale={\n",
        "            type=\"log\",\n",
        "            scheme=\"blues\",\n",
        "          },\n",
        "          legend={\n",
        "            title=\"Runtime Overhead (X)\",\n",
        "            orient=\"top\",\n",
        "            titleLimit=1000,\n",
        "            gradientLength=540,\n",
        "            titleAnchor=\"center\",\n",
        "            titleAlign=\"center\",\n",
        "          },\n",
        "        },\n",
        "        },\n",
        "        \n",
        "      },\n",
        "      {\n",
        "        mark={\n",
        "          type=\"text\",\n",
        "          fontSize=\"6\",\n",
        "        },\n",
        "        encoding={\n",
        "          y={\n",
        "            field=\"analysis\",\n",
        "            type=\"nominal\",\n",
        "          },\n",
        "          x={\n",
        "            field=\"input_program\",\n",
        "            type=\"nominal\",\n",
        "            axis={title=\"Input Program\",},\n",
        "          },\n",
        "          text={\n",
        "            field=\"text_report_truncated\",\n",
        "            type=\"nominal\",\n",
        "          },\n",
        "        },\n",
        "      },\n",
        "    ],\n",
        "\n",
        "  },\n",
        "  config={\n",
        "    axis={\n",
        "      grid=true,\n",
        "      tickBand=\"extent\",\n",
        "    },\n",
        "  },\n",
        ")\n",
        "\n",
        "\n",
        "all_performance_overhead_plot |> save(target_dir_prefix * \"wastrumentation-wasabi-runtime-overhead-single.pdf\")\n",
        "all_performance_overhead_plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_wasabi_wastrm_joined = innerjoin(\n",
        "  rename(df_wastrm_aggregated, :completion_time  => :wastrm_completion_time,\n",
        "                               :exception        => :wastrm_exception,\n",
        "                               :exception_reason => :wastrm_exception_reason,\n",
        "                               :timeout          => :wastrm_timeout,\n",
        "                               :timeout_amount   => :wastrm_timeout_amount),\n",
        "  rename(df_wasabi_aggregated, :completion_time  => :wasabi_completion_time,\n",
        "                               :exception        => :wasabi_exception,\n",
        "                               :exception_reason => :wasabi_exception_reason,\n",
        "                               :timeout          => :wasabi_timeout,\n",
        "                               :timeout_amount   => :wasabi_timeout_amount),\n",
        "  on=[:runtime, :analysis, :input_program],\n",
        ")\n",
        "\n",
        "df_wasabi_wastrm_runtime_relative = transform(\n",
        "    df_wasabi_wastrm_joined,\n",
        "    [:wastrm_completion_time, :wastrm_exception, :wastrm_exception_reason, :wastrm_timeout, :wastrm_timeout_amount, :wasabi_completion_time, :wasabi_exception, :wasabi_exception_reason, :wasabi_timeout, :wasabi_timeout_amount,] =>\n",
        "    ByRow((wastrm_completion_time, wastrm_exception, wastrm_exception_reason, wastrm_timeout, wastrm_timeout_amount, wasabi_completion_time, wasabi_exception, wasabi_exception_reason, wasabi_timeout, wasabi_timeout_amount) -> \n",
        "    begin\n",
        "      if wastrm_exception || wastrm_timeout || wasabi_exception || wasabi_timeout\n",
        "        if wastrm_exception && wasabi_exception\n",
        "          [missing, \"MD:M&S\"]\n",
        "        elseif wastrm_timeout && wasabi_timeout\n",
        "          [missing, \"T:M&S\"]\n",
        "        elseif wastrm_exception && wasabi_timeout\n",
        "          [missing, \"MD:M,T:S\"]\n",
        "        elseif wastrm_timeout && wasabi_exception\n",
        "          [missing, \"T:M,MD:S\"]\n",
        "        elseif wastrm_exception\n",
        "          [missing, \"MD:M\"]\n",
        "        elseif wasabi_exception\n",
        "          [missing, \"MD:S\"]\n",
        "        elseif wastrm_timeout\n",
        "          [missing, \"T:M\"]\n",
        "        elseif wasabi_timeout\n",
        "          [missing, \"T:S\"]\n",
        "        end\n",
        "      else\n",
        "        relative_performance = wasabi_completion_time / wastrm_completion_time\n",
        "        [relative_performance, @sprintf(\"%.4g\", relative_performance)]\n",
        "    end\n",
        "    end)\n",
        "    => [:wasabi_perf_per_wastrm_perf, :text_report]\n",
        ")\n",
        "\n",
        "\"computed\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_wasabi_wastrm_runtime_relative_plot = df_wasabi_wastrm_runtime_relative |> @vlplot(\n",
        "  \"transform\"=[\n",
        "    {\n",
        "      \"calculate\"=\"substring(datum.text_report, 0, 5)\",\n",
        "      \"as\"=\"text_report_truncated\"\n",
        "    },\n",
        "  ],\n",
        "  encoding={\n",
        "    y={\n",
        "      field=\"analysis\",\n",
        "      type=\"nominal\",\n",
        "      axis={labelAngle=\"-30\"},\n",
        "    },\n",
        "    x={\n",
        "      field=\"input_program\",\n",
        "      type=\"nominal\",\n",
        "      axis={title=\"Input Program\",labelAngle=\"-30\"},\n",
        "    },\n",
        "  },\n",
        "  layer=[\n",
        "    {\n",
        "      mark=\"rect\",\n",
        "      encoding={\n",
        "        color={\n",
        "          field=\"wasabi_perf_per_wastrm_perf\",\n",
        "          type=\"quantitative\",\n",
        "          scale={\n",
        "            type=\"log\",\n",
        "            domainMid=1,\n",
        "            scheme=\"redyellowgreen\",\n",
        "          },\n",
        "          legend={\n",
        "            title=\"Wasabi Execution Time / Wastrumentation Execution Time\",\n",
        "            orient=\"top\",\n",
        "            titleLimit=1000,\n",
        "            gradientLength=400,\n",
        "            titleAnchor=\"center\",\n",
        "            titleAlign=\"center\",\n",
        "          },\n",
        "        },\n",
        "      },\n",
        "    },\n",
        "    {\n",
        "      mark={\n",
        "        type=\"text\",\n",
        "        fontSize=\"6\",\n",
        "      },\n",
        "      encoding={\n",
        "        text={\n",
        "          field=\"text_report_truncated\",\n",
        "          type=\"nominal\",\n",
        "        },\n",
        "      },\n",
        "    },\n",
        "  ],\n",
        "  config={\n",
        "    axis={grid=true, tickBand=\"extent\",}\n",
        "  },\n",
        ")\n",
        "\n",
        "df_wasabi_wastrm_runtime_relative_plot |> save(target_dir_prefix * \"df-wasabi-wastrm-runtime-relative.pdf\")\n",
        "df_wasabi_wastrm_runtime_relative_plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "MD_MS    = nrow(filter(:text_report => (tr) -> tr .=== \"MD:M&S\"  , df_wasabi_wastrm_runtime_relative))\n",
        "T_MS     = nrow(filter(:text_report => (tr) -> tr .=== \"T:M&S\"   , df_wasabi_wastrm_runtime_relative))\n",
        "MD_M_T_S = nrow(filter(:text_report => (tr) -> tr .=== \"MD:M,T:S\", df_wasabi_wastrm_runtime_relative))\n",
        "T_M_MD_S = nrow(filter(:text_report => (tr) -> tr .=== \"T:M,MD:S\", df_wasabi_wastrm_runtime_relative))\n",
        "MD_M     = nrow(filter(:text_report => (tr) -> tr .=== \"MD:M\"    , df_wasabi_wastrm_runtime_relative))\n",
        "MD_S     = nrow(filter(:text_report => (tr) -> tr .=== \"MD:S\"    , df_wasabi_wastrm_runtime_relative))\n",
        "T_M      = nrow(filter(:text_report => (tr) -> tr .=== \"T:M\"     , df_wasabi_wastrm_runtime_relative))\n",
        "T_S      = nrow(filter(:text_report => (tr) -> tr .=== \"T:S\"     , df_wasabi_wastrm_runtime_relative))\n",
        "\n",
        "passed   = nrow(filter(:wasabi_perf_per_wastrm_perf => (tr) -> tr .!== missing, df_wasabi_wastrm_runtime_relative))\n",
        "total    = nrow(df_wasabi_wastrm_runtime_relative)\n",
        "\n",
        "@assert MD_MS    == 0\n",
        "# @assert T_MS     == 0 => not null\n",
        "@assert MD_M_T_S == 0\n",
        "@assert T_M_MD_S == 0\n",
        "@assert MD_M     == 0\n",
        "@assert MD_S     == 0\n",
        "# @assert T_M      == 0 => not null\n",
        "# @assert T_S      == 0 => not null\n",
        "\n",
        "sentence = \"\n",
        "We summarize the labels and occurences.\n",
        "For a total of $(total) combinations where both Wastrumentation and Wasabi yield a valid instrumented module, $(passed) combinations yield a measurement.\n",
        "For $(T_MS) combinations both Wastrumentation and Wasabi timeout.\n",
        "For $(T_M) combinations only Wastrumentation reports a timeout.\n",
        "For $(T_S) combinations only Wastrumentation reports a timeout.\n",
        "\"\n",
        "\n",
        "println(sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Let's do the same performance evaluation, but now take the first run!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "# baseline =\n",
        "#     rename(\n",
        "#       select(\n",
        "#         subset(df_rgular, :runtime_iteration => i -> i .== 1),\n",
        "#         Not([:setup]),\n",
        "#       ),\n",
        "#       :performance => :performance_baseline,\n",
        "#     )\n",
        "\n",
        "# df_wasabi_timeout_computed = df_wasabi\n",
        "# df_wastrm_timeout_computed = df_wastrm\n",
        "\n",
        "# if isa(df_wasabi.performance, Vector{String})\n",
        "#   df_wasabi_timeout_computed = transform(df_wasabi, :performance => ByRow((x) -> parse(Float64, x == \"timeout 10s\" ? \"10000\" : x)) => :performance)\n",
        "# end\n",
        "# if isa(df_wastrm.performance, Vector{String})\n",
        "#   df_wastrm_timeout_computed = transform(df_wastrm, :performance => ByRow((x) -> parse(Float64, x == \"timeout 10s\" ? \"10000\" : x)) => :performance)\n",
        "# end\n",
        "\n",
        "# @assert isa(df_wasabi_timeout_computed.performance, Vector{Float64}) \"df_wasabi should be parsed to Float64\"\n",
        "# @assert isa(df_wastrm_timeout_computed.performance, Vector{Float64}) \"df_wasabi should be parsed to Float64\"\n",
        "\n",
        "# using Statistics\n",
        "\n",
        "# # Aggregate computations per 'run'!\n",
        "# df_wasabi_aggr = combine(groupby(df_wasabi_timeout_computed, Cols(:runtime_iteration, :setup, :runtime, :input_program, \"time-unit\")), :performance => median => :performance)\n",
        "# df_wastrm_aggr = combine(groupby(df_wastrm_timeout_computed, Cols(:runtime_iteration, :setup, :runtime, :input_program, \"time-unit\")), :performance => median => :performance)\n",
        "\n",
        "# df_wasabi_sep_analyses = transform(\n",
        "#   df_wasabi_aggr,\n",
        "#   :setup => ByRow(setup -> match(r\"\\[wasabi - (.+)\\]\", setup).captures[1]) => :analysis,\n",
        "#   :setup => (_ -> \"wasabi\") => :setup,\n",
        "# )\n",
        "# df_wastrm_sep_analyses = transform(\n",
        "#   df_wastrm_aggr,\n",
        "#   :setup => ByRow(setup -> match(r\"\\[wastrumentation - (.+)\\]\", setup).captures[1]) => :analysis,\n",
        "#   :setup => (_ -> \"wastrumentation\") => :setup,\n",
        "# )\n",
        "\n",
        "# df_wasabi_instruction_overhead = select(\n",
        "#   innerjoin(baseline, df_wasabi_sep_analyses, on=[:input_program, :runtime, :runtime_iteration, \"time-unit\"]),\n",
        "#   [:performance, :performance_baseline]\n",
        "#     => ((performance, performance_baseline) -> performance ./ performance_baseline)\n",
        "#     => :overhead,\n",
        "#   # What to keep:\n",
        "#   :input_program, :setup, :analysis,\n",
        "# )\n",
        "\n",
        "# df_wastrm_instruction_overhead = select(\n",
        "#   innerjoin(baseline, df_wastrm_sep_analyses, on=[:input_program, :runtime, :runtime_iteration, \"time-unit\"]),\n",
        "#   [:performance, :performance_baseline]\n",
        "#     => ((performance, performance_baseline) -> performance ./ performance_baseline)\n",
        "#     => :overhead,\n",
        "#   # What to keep:\n",
        "#   :input_program, :setup, :analysis,\n",
        "# )\n",
        "\n",
        "# # Aggregate all overhead\n",
        "# df_wasabi_instruction_overhead_single = combine(groupby(df_wasabi_instruction_overhead, Cols(:input_program, :setup, :analysis)), :overhead => median => :overhead)\n",
        "# df_wastrm_instruction_overhead_single = combine(groupby(df_wastrm_instruction_overhead, Cols(:input_program, :setup, :analysis)), :overhead => median => :overhead)\n",
        "\n",
        "# df_wasabi_wastrm_overhead = transform(\n",
        "#   innerjoin(\n",
        "#     rename(select(df_wasabi_instruction_overhead_single, Not(:setup)), :overhead => :overhead_wasabi),\n",
        "#     rename(select(df_wastrm_instruction_overhead_single, Not(:setup)), :overhead => :overhead_wastrm),\n",
        "#     on=[:input_program, :analysis]\n",
        "#   ),\n",
        "#   [:overhead_wasabi, :overhead_wastrm]\n",
        "#     => ((overhead_wasabi, overhead_wastrm) -> overhead_wasabi ./ overhead_wastrm)\n",
        "#     => :time_for_wasabi_per_time_for_wastrm,\n",
        "# )\n",
        "\n",
        "# df_wasabi_wastrm_overhead = transform(\n",
        "#   df_wasabi_wastrm_overhead,\n",
        "#   :time_for_wasabi_per_time_for_wastrm\n",
        "#   =>\n",
        "#   ByRow(performance_comparison)\n",
        "#   =>\n",
        "#   :time_for_wasabi_per_time_for_wastrm,\n",
        "# ) |>\n",
        "# @vlplot(\n",
        "#   :rect,\n",
        "#   encoding={\n",
        "#     color={\n",
        "#       field=\"time_for_wasabi_per_time_for_wastrm\",\n",
        "#       type=\"ordinal\",\n",
        "#       scale={\n",
        "#         scheme=\"blueorange\",\n",
        "#         domain=performance_ordinal_domain\n",
        "#       },\n",
        "#     },\n",
        "#     x={\n",
        "#       field=\"analysis\",\n",
        "#       type=\"nominal\",\n",
        "#     },\n",
        "#     y={\n",
        "#       field=\"input_program\",\n",
        "#       type=\"nominal\",\n",
        "#     },\n",
        "#   },\n",
        "#   config={\n",
        "#     spacing=100,\n",
        "#     view={stroke=:transparent},\n",
        "#     axis={domainWidth=1}\n",
        "#   },\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Memoization Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "exit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "using Pkg\n",
        "Pkg.add(\"CSV\")\n",
        "\n",
        "using CSV\n",
        "using DataFrames\n",
        "using Dates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_memoization_performance = DataFrame(load(target_dir_prefix * \"memoization_performance_wasmr3.csv\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "function parse_time_to_ms(time :: String)\n",
        "  if time === \"NA\"\n",
        "    missing\n",
        "  elseif occursin(\"ms\", time)\n",
        "    time_element = match(r\"(\\d+\\.?\\d*)ms\", time).captures[1]\n",
        "    parse(Float64, time_element)\n",
        "  elseif occursin(\"s\", time)\n",
        "    time_element = match(r\"(\\d+.?\\d*)s\", time).captures[1]\n",
        "    parse(Float64, time_element) * 1000\n",
        "  else\n",
        "    error(\"Could not parse $time\")\n",
        "  end\n",
        "end\n",
        "\n",
        "# Apply the parsing function to the columns\n",
        "df_memoization_performance.uninstrumented = parse_time_to_ms.(df_memoization_performance.uninstrumented)\n",
        "df_memoization_performance.instrumented = parse_time_to_ms.(df_memoization_performance.instrumented)\n",
        "\n",
        "\"Interpretation done\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_memoization_performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_memoization_performance_overhead = transform(\n",
        "    df_memoization_performance,\n",
        "    [:instrumented, :uninstrumented] => ByRow((instrumented, uninstrumented) ->\n",
        "        if instrumented !== missing && uninstrumented !== missing\n",
        "            instrumented / uninstrumented\n",
        "        else\n",
        "            missing\n",
        "        end\n",
        "    ) => :overhead,\n",
        ")\n",
        "\n",
        "df_non_missing_memoization_performance_overhead = filter(row -> row.overhead !== missing, df_memoization_performance_overhead)\n",
        "\n",
        "df_memoization_performance_overhead_slower = filter(row -> row.overhead > 1, df_non_missing_memoization_performance_overhead)\n",
        "df_memoization_performance_overhead_faster = filter(row -> row.overhead < 1, df_non_missing_memoization_performance_overhead)\n",
        "df_memoization_performance_overhead_faster = transform(\n",
        "    df_memoization_performance_overhead_faster,\n",
        "    [:instrumented, :uninstrumented] => ByRow((instrumented, uninstrumented) -> uninstrumented / instrumented) => :overhead,\n",
        ")\n",
        "\"Interpreted all speedups and slowdowns\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_memoization_performance_overhead_slower"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_memoization_performance_overhead_faster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "least_slower = df_memoization_performance_overhead_slower[argmin(df_memoization_performance_overhead_slower.overhead), :]\n",
        "hghst_slower = df_memoization_performance_overhead_slower[argmax(df_memoization_performance_overhead_slower.overhead), :]\n",
        "least_slower_prog = least_slower.input_program\n",
        "least_slower_vlue = least_slower.overhead\n",
        "hghst_slower_prog = hghst_slower.input_program\n",
        "hghst_slower_vlue = hghst_slower.overhead\n",
        "\n",
        "least_faster = df_memoization_performance_overhead_faster[argmin(df_memoization_performance_overhead_faster.overhead), :]\n",
        "hghst_faster = df_memoization_performance_overhead_faster[argmax(df_memoization_performance_overhead_faster.overhead), :]\n",
        "least_faster_prog = least_faster.input_program\n",
        "least_faster_vlue = least_faster.overhead\n",
        "hghst_faster_prog = hghst_faster.input_program\n",
        "hghst_faster_vlue = hghst_faster.overhead\n",
        "\n",
        "sentence = \"\n",
        "Our benchmarks on the memoization analysis show that the analysis can incur a performance penalty but can also speed up the input program execution.\n",
        "The performance penalty ranges from $(@sprintf(\"%.2f\", least_slower_vlue))x slowdown ($least_slower_prog) to $(@sprintf(\"%.2f\", hghst_slower_vlue))x slowdown ($hghst_slower_prog).\n",
        "The speed up ranges from $(@sprintf(\"%.2f\", least_faster_vlue))x speedup ($least_faster_prog) to $(@sprintf(\"%.2f\", hghst_faster_vlue))x speedup ($hghst_faster_prog).\n",
        "\"\n",
        "\n",
        "println(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split the columns for 'uninstrumented' and 'instrumented' and make them two DF's that we then append to each other\n",
        "df_memoization_uninstrumented = select(df_memoization_performance, :input_program, :uninstrumented)\n",
        "df_memoization_instrumented = select(df_memoization_performance, :input_program, :instrumented)\n",
        "\n",
        "rename!(df_memoization_uninstrumented, :uninstrumented => :runtime)\n",
        "rename!(df_memoization_instrumented, :instrumented => :runtime)\n",
        "\n",
        "df_memoization_uninstrumented[!, :type] .= \"uninstrumented\"\n",
        "df_memoization_instrumented[!, :type] .= \"instrumented\"\n",
        "\n",
        "df_memoization_combined = vcat(df_memoization_uninstrumented, df_memoization_instrumented)\n",
        "\"Merged results into single view\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_memoization_combined_type_renamed = transform(df_memoization_combined, :type => ByRow((type) -> begin\n",
        "    if type .=== \"uninstrumented\"\n",
        "        \"Regular Execution\"\n",
        "    elseif  type .=== \"instrumented\"\n",
        "        \"Memoized Execution\"\n",
        "    else\n",
        "        error(\"Unknown case in $type\")\n",
        "    end\n",
        "end) => :type)\n",
        "\"Renamed\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_memoization_combined_plot = df_memoization_combined_type_renamed |> @vlplot(\n",
        "  mark={\n",
        "      type=\"bar\",\n",
        "      cornerRadiusEnd=3,  # Adds rounded corners at the top of each bar\n",
        "  },\n",
        "  encoding={\n",
        "    color={\n",
        "      field=\"type\",\n",
        "      type=\"nominal\",\n",
        "      scale={\n",
        "          scheme=\"pastel2\",  # Color scheme for distinct colors that are accessible\n",
        "          # range=[\"instrumented\", \"uninstrumented\"],  # Original values in `type`\n",
        "          # domain=[\"Memoized Execution\", \"Regular Execution\"],  # Custom legend names\n",
        "      },\n",
        "      legend={\n",
        "        title=\"Execution model\",\n",
        "        orient=\"top\",\n",
        "        titleFontSize=12,\n",
        "        labelFontSize=10,\n",
        "      }\n",
        "    },\n",
        "    xOffset={\n",
        "      field=\"type\",\n",
        "      type=\"nominal\",\n",
        "    },\n",
        "    x={\n",
        "      field=\"input_program\",\n",
        "      type=\"nominal\",\n",
        "      axis={\n",
        "        title=\"Input Program\",\n",
        "        labelAngle=-30,\n",
        "        labelFontSize=10,\n",
        "        titleFontSize=12,\n",
        "        titlePadding=10,\n",
        "      },\n",
        "    },\n",
        "    y={\n",
        "      field=\"runtime\",\n",
        "      type=\"quantitative\",\n",
        "      axis={\n",
        "        title=\"Runtime (ms)\",\n",
        "        titleFontSize=12,\n",
        "        labelFontSize=10,\n",
        "        grid=false, # Removes y-axis gridlines for a cleaner look\n",
        "      },\n",
        "      scale={\n",
        "        type=\"log\",\n",
        "      },\n",
        "    },\n",
        "  },\n",
        "  title=\"Runtime Comparison for Regular Execution and Memoized Execution\",  # Adds a descriptive title\n",
        "  config={\n",
        "    axis={\n",
        "      domainColor=\"#999\",  # Lightens axis lines for a cleaner look\n",
        "    },\n",
        "    view={stroke=:transparent},\n",
        "  }\n",
        ")\n",
        "\n",
        "df_memoization_combined_plot |> save(target_dir_prefix * \"memoization-over-head-plot.pdf\")\n",
        "df_memoization_combined_plot"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Julia 1.11.1",
      "language": "julia",
      "name": "julia-1.11"
    },
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia",
      "version": "1.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
